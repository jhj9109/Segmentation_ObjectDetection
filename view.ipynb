{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f1e0ec-38f4-427d-806f-982d932478a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [00:14<00:00, 57.56it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='')\n",
    "# parser.add_argument('--f', required=False, default='submission.csv')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "root_dir = '/opt/ml/input/data/'\n",
    "save_path = '/opt/ml/code/mmdetection_trash/submission_image2'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# df = pd.read_csv(f'/opt/ml/code/mmdetection_trash/{args.f}')\n",
    "d1 = 'detectors_x101_64x4d_adam2'\n",
    "d2 = 'detectors_x101_64x4d_adam2_epoch18'\n",
    "df = pd.read_csv(f'/opt/ml/code/mmdetection_trash/work_dirs/{d2}.csv')\n",
    "# df = pd.read_csv(f'/opt/ml/code/mmdetection_trash/en4.csv')\n",
    "image_id = df.image_id\n",
    "prediction_string = df.PredictionString\n",
    "\n",
    "classes = (\"UNKNOWN\", \"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "COLORS = [\n",
    "    (39, 129, 113), \n",
    "    (164, 80, 133), \n",
    "    (83, 122, 114), \n",
    "    (99, 81, 172), \n",
    "    (95, 56, 104), \n",
    "    (37, 84, 86), \n",
    "    (14, 89, 122),\n",
    "    (80, 7, 65), \n",
    "    (10, 102, 25), \n",
    "    (90, 185, 109),\n",
    "    (106, 110, 132)\n",
    "]\n",
    "\n",
    "for i in tqdm(range(837)):    \n",
    "    img_path = os.path.join(root_dir, image_id[i])\n",
    "    # print(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    annot = prediction_string[i].split(' ')\n",
    "    annot = [annot[i * 6:(i + 1) * 6] for i in range((len(annot) + 6 - 1) // 6 )] \n",
    "    annot.remove([''])\n",
    "    output_img = img.copy()\n",
    "    for bbox in annot:\n",
    "        if 'nan' in bbox:\n",
    "            print(image_id[i])\n",
    "            continue\n",
    "        bbox = list(map(float, bbox))\n",
    "        bbox = np.array(bbox).astype(int)\n",
    "        label = int(bbox[0])\n",
    "        xmin, ymin, xmax, ymax = bbox[2:6]\n",
    "\n",
    "        color = COLORS[label]\n",
    "        cv2.rectangle(output_img, (xmin, ymin), (xmax, ymax), color, 2)        \n",
    "        text_size = cv2.getTextSize(classes[label], cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "        cv2.rectangle(output_img, (xmin, ymin), (xmin + text_size[0] + 2, ymin + text_size[1] + 6), color, -1)\n",
    "        cv2.putText(\n",
    "            output_img, classes[label],\n",
    "            (xmin, ymin + text_size[1] + 4), cv2.FONT_ITALIC, 0.5,\n",
    "            (255, 255, 255), 1, cv2.LINE_AA)        \n",
    "    result_img = np.concatenate((img, output_img), axis=1)\n",
    "    \n",
    "    cv2.imwrite(os.path.join(save_path, image_id[i].replace('/', '-')), result_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8362b6-470a-4bf7-b816-00d73b2227b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dict()\n",
    "model['resnet50'] = dict(pretrained='torchvision://resnet50',\n",
    "                         backbone=dict(type='ResNet',\n",
    "                                       depth=50,\n",
    "                                       num_stages=4,\n",
    "                                       out_indices=(0, 1, 2, 3),\n",
    "                                       frozen_stages=1,\n",
    "                                       norm_cfg=dict(type='BN', requires_grad=True),\n",
    "                                       norm_eval=True,\n",
    "                                       style='pytorch'))\n",
    "model['resnset50_caffe'] = dict(pretrained='open-mmlab://detectron2/resnet50_caffe',\n",
    "                                backbone=dict(type='ResNet',\n",
    "                                              depth=50,\n",
    "                                              num_stages=3,\n",
    "                                              strides=(1, 2, 2),\n",
    "                                              dilations=(1, 1, 1),\n",
    "                                              out_indices=(2, ),\n",
    "                                              frozen_stages=1,\n",
    "                                              norm_cfg=norm_cfg,\n",
    "                                              norm_eval=True,\n",
    "                                              style='caffe'),\n",
    "                \n",
    "model['resnet101_caffe'] = dict(pretrained = 'open-mmlab://detectron2/resnet101_caffe',\n",
    "                                backbone = dict(depth=101))\n",
    "model['resnet101'] = dict(pretrained='torchvision://resnet101',\n",
    "                          backbone=dict(depth=101))\n",
    "model['resnet50_caffe'] = dict(pretrained='open-mmlab://detectron2/resnet50_caffe',\n",
    "                               backbone=dict(norm_cfg=dict(requires_grad=False), norm_eval=True, style='caffe'))\n",
    "model['resnet50_caffe'] = dict(pretrained='open-mmlab://detectron2/resnet50_caffe',\n",
    "                                backbone=dict(norm_cfg=dict(requires_grad=False), norm_eval=True, style='caffe'),\n",
    "                                roi_head=dict(bbox_head=dict(num_classes=1)))\n",
    "model = dict(roi_head=dict(bbox_head=dict(reg_decoded_bbox=True,\n",
    "                                          loss_bbox=dict(type='BoundedIoULoss', loss_weight=10.0))))\n",
    "model['resnext101'] = dict(pretrained='open-mmlab://resnext101_32x4d',\n",
    "                        backbone=dict(type='ResNeXt',\n",
    "                                      depth=101,\n",
    "                                      groups=32,\n",
    "                                      base_width=4,\n",
    "                                      num_stages=4,\n",
    "                                      out_indices=(0, 1, 2, 3),\n",
    "                                      frozen_stages=1,\n",
    "                                      norm_cfg=dict(type='BN', requires_grad=True),\n",
    "                                      style='pytorch'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
